import requests
from bs4 import BeautifulSoup

import pymongo
client=pymongo.MongoClient('localhost',27017)
item_info=client['item_info']
item_urls=item_info['item_urls']
item_infos=item_info['item_infos']
headers={

    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36'

}
def get_links_from(channel,page,who_shells=0):
    # https://sz.58.com/shouji/0/pn2
    list_view='{}{}/pn{}/'.format(channel,str(who_shells),str(page))
    web_data=requests.get(list_view,headers=headers)
    soup=BeautifulSoup(web_data.text,'lxml')


    if soup.find('td','t'):
        for item in soup.select('td.t a.t'):
                item_link=item.get('href').split('?')[0]
                item_urls.insert_one({'url':item_link})
    else:
        pass

def get_info(url):

    web_data = requests.get(url,headers=headers)
    soup = BeautifulSoup(web_data.text, 'lxml')
    str1 = '面议'
    pass_url =soup.select('span.infocard__container__item__main__text--price')[0].text.strip()
    if pass_url==str1:
        pass
    else:
        title=soup.title.text
        time=soup.select('div.detail-title__info > div.detail-title__info__text')[0].text
        price=soup.select('span.infocard__container__item__main__text--price')[0].text.strip()
        area=soup.select('.infocard__container__item__main a')[0].text
        area1=soup.select('.infocard__container__item__main a')[1].text
        area=str(area)+'-'+str(area1)

        item_infos.insert_one({'title':title,'price':price,'area':area})
        print({'time':time,'title':title,'price':price,'area':area})


# get_links_from('https://sz.58.com/shouji/',2)
# get_info('https://sz.58.com/shouji/42072586614790x.shtml')
# get_info('https://sz.58.com/shouji/42982449363462x.shtml')
